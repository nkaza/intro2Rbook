# Data in R {#data_r}

Until now, you've created fairly simple data in R and stored it as a [vector](#funcs). However, most (if not all) of you will have much more complicated datasets from your various experiments and surveys that go well beyond what a vector can handle. Learning how R deals with different types of data and data structures, how to import your data into R and how to manipulate and summarise your data are some of the most important skills you will need to master. 

In this Chapter we'll go over the main data types in R and focus on some of the most common data structures. We will also cover how to import data into R from an external file, how to manipulate (wrangle) and summarise data and finally how to export data from R to an external file.

## Basic Data types

Understanding the different types of data and how R deals with these data is important. The temptation is to glaze over and skip these technical details, but beware, this can come back to bite you somewhere unpleasant if you don't pay attention. We've already seen an [example](#r_objs) of this when we tried (and failed) to add two character objects together using the `+` operator.

R has six basic types of data; numeric, integer, logical, complex and character. The keen eyed among you will notice we've only listed five data types here, the final data type is raw which we won't cover as it's not useful 99.99% of the time. We also won't cover complex numbers as we don't have the [imagination][complex_num]!

\  

  - **Numeric** data are numbers that contain a decimal. Actually they can also be whole numbers but we'll gloss over that.

  - **Integers** are whole numbers (those numbers without a decimal point).

  - **Logical** data take on the value of either `TRUE` or `FALSE`. There's also another special type of logical called `NA` to represent missing values.

  - **Character** data are used to represent string values. You can think of character strings as something like a word (or multiple words). A special type of character string is a *factor*, which is a string but with additional attributes (like levels or an order). We'll cover factors later. 

\  

R is (usually) able to automatically distinguish between different classes of data by their nature and the context in which they're used although you should bear in mind that R can't actually read your mind and you may have to explicitly tell R how you want to treat a data type. You can find out the type (or class) of any object using the `class()`\index{class()} function.

```{r, echo=TRUE, eval=TRUE, collapse=TRUE}

int <- 2L # Need to include L to specify integer
class(int)

num <- 2
class(num)

identical(int, num) # Check to see if int and num are identical

all.equal(int, num) # On most machines this will be true

char <- "hello"
class(char)

logi <- TRUE
class(logi)
```

Alternatively, you can ask if an object is a specific class using using a logical test. The `is.[classOfData]()` family of functions will return either a `TRUE` or a `FALSE`.\index{is.numeric()} \index{is.character()} \index{is.logical()}

```{r, echo=TRUE, eval=TRUE, collapse=TRUE}
is.numeric(num)

is.character(num)

is.character(char)

is.logical(logi)
```

It can sometimes be useful to be able to change the class of a variable using the `as.[className]()` family of coercion functions, although you need to be careful when doing this as you might receive some unexpected results (see what happens below when we try to convert a character string to a numeric). \index{as.character()} \index{as.numeric()} \index{as.logical()} \index{as.factor()} \index{as.complex()}
 
```{r, echo=TRUE, eval=TRUE, collapse=TRUE}
# coerce numeric to character
class(num)
num_char <-  as.character(num)
num_char
class(num_char)

# coerce character to numeric!
class(char)
char_num <- as.numeric(char)
```

Here's a summary table of some of the logical test and coercion functions available to you.\index{is.numeric()} \index{is.factor()}

|     Type       |    Logical test       |     Coercing       |
|:--------------:|:-------------------:|:-----------------:|
|  Character     |   `is.character`   |   `as.character`   |
|  Numeric   |   `is.numeric`   |   `as.numeric`   |
|  Logical | `is.logical` | `as.logical` |
|  Factor   |   `is.factor`  |   `as.factor`  |
|  Complex     |   `is.complex`    |   `as.complex`    |


## Complicated Data Types

There are lots of complicated data types in R. But the two we will be faced with frequently are time/date and factors.

### Dealing with Date and Time

Often dates and time pose significant problems to students, because of the complicated background that undergirds them to make them legible. For example,


```{r, echo=TRUE, eval=TRUE, collapse=TRUE}
date_of_collection <- 2022-08-31

date_of_collection

class(date_of_collection)
```

 Because `-` is typically interpreted as subtraction rather than as an en dash or a hyphen, R treats is as a calculator. You can get around it by enclosing in quotes and converting to character, but that looses the ability to do arithmetic
 
```{r, echo=TRUE, eval=FALSE, collapse=TRUE}
date_of_collection <- "2022-08-31"

class(date_of_collection)
# > [1] "Character"

date_of_collection + 2
# > Error in date_of_collection + 2 : non-numeric argument to binary operator


```

You will have to explicitly specify that you want to store the date as a type. I strongly recommend using the `lubridate` package

```{r, echo=TRUE, eval=TRUE, collapse=TRUE}
library(lubridate)

date_of_collection <- as_date("2022-08-31")

class(date_of_collection)

Sys.Date() - date_of_collection

```

In R, dates are represented as the number of days since 1970-01-01.

```{r, echo=TRUE, eval=TRUE, collapse=TRUE}
unclass(date_of_collection)
```

 Time is even more complicated than dates, as times need to have time zones associated with them as well as potential offsets such as daylight savings. In particular, I recommend, the `ymd_hms` type functions in lubridate to convert the character into a time object. More on this later.
 
```{r, echo=TRUE, eval=TRUE, collapse=TRUE}

time_of_collection <- ymd_hms("2010-12-13 15:30:30")
time_of_collection


# Changes printing
with_tz(time_of_collection, "America/Los_Angeles")


# Changes time
force_tz(time_of_collection, "America/Chicago")

```

Time Zones are complicated. Over the last 100 years places have changed their affiliation between major time zones, have opted out of (or in to) daylight savings time (DST) in various years or adopted DST rule changes late or not at all. (The UK experimented with DST throughout 1971, only.) In a few countries (one is the Irish Republic) it is the summer time which is the ‘standard’ time and a different name is used in winter. And there can be multiple changes during a year, for example for Ramadan. These should be documented as part of the data collection and metadata processes.

### Factors

R uses factors to handle categorical variables, variables that have a fixed and known set of possible values. Factors are also helpful for reordering character vectors to improve display. Factors are stored as integers rather than characters. For example, you can have day of the week as a factor variable.

```{r, echo=TRUE, eval=TRUE, collapse=TRUE}
day_of_week <- c('M', 'M', 'T', 'TH', 'W', 'SA', 'SU', 'TH')

(day_of_week <- factor(day_of_week))

```

Components of a factor can be modified using simple assignments. However values outside of its predefined levels are not permitted. Instead need to modify the levels first.


```{r, echo=TRUE, eval=TRUE, collapse=TRUE}
day_of_week[3] <- 'W'

day_of_week

day_of_week[4] <- 'F'

levels(day_of_week) <- c(levels(day_of_week), "F")    # add new level
day_of_week[4] <- 'F'

str(day_of_week)

```

Reordering the levels is often useful, especially for plotting purposes.


```{r, echo=TRUE, eval=TRUE, collapse=TRUE}
day_of_week <- c('M', 'M', 'T', 'TH', 'W', 'SA', 'SU', 'TH') %>% factor

str(day_of_week)

day_of_week <- factor(day_of_week, levels=c("SU", "M", "T", "W", "TH", "F", "SA"))

str(day_of_week)

```




## Data structures

Now that you've been introduced to some of the most important classes of data in R, let’s have a look at some of main structures that we have for storing these data. 

### Scalars and vectors {#scal_vecs}

Perhaps the simplest type of data structure is the vector. You've already been introduced to vectors in [Chapter 2](#funcs) although some of the vectors you created only contained a single value. Vectors that have a single value (length 1) are called scalars. Vectors can contain numbers, characters, factors or logicals, but the key thing to remember is that all the elements inside a vector must be of the same class. In other words, vectors can contain either numbers, characters or logicals but not mixtures of these types of data. There is one important exception to this, you can include `NA` (remember this is special type of logical) to denote missing data in vectors with other data types. 

\  

```{r data_struc, echo=FALSE, out.width="40%", fig.align="center"}
knitr::include_graphics(path = "images/scal_vec.png")
```

### Matrices and arrays {#mat_array}

Another useful data structure used in many disciplines is the matrix. A matrix is simply a vector that has additional attributes called dimensions. Arrays are just multidimensional matrices. Again, matrices and arrays must contain elements all of the same data class.

\  

```{r data_struc2, echo=FALSE, out.width="50%", fig.align="center"}
knitr::include_graphics(path = "images/mat_array.png")
```

\ 

A convenient way to create a matrix or an array is to use the `matrix()`\index{martix()} and `array()`\index{array()} functions respectively. Below, we will create a matrix from a sequence 1 to 16 in four rows (`nrow = 4`) and fill the matrix row-wise (`byrow = TRUE`) rather than the default column-wise. When using the `array()` function we define the dimensions using the `dim =` argument, in our case 2 rows, 4 columns in 2 different matrices.   

```{r, echo=TRUE, eval=TRUE, collapse=TRUE}
my_mat <- matrix(1:16, nrow = 4, byrow = TRUE)
my_mat

my_array <- array(1:16, dim = c(2, 4, 2))
my_array
```

Sometimes it's also useful to define row and column names for your matrix but this is not a requirement. To do this use the `rownames()`\index{rownames()} and `colnames()`\index{colnames()} functions.

```{r, echo=TRUE, eval=TRUE, collapse=TRUE}
rownames(my_mat) <- c("A", "B", "C", "D")
colnames(my_mat) <- c("a", "b", "c", "d")
my_mat
```

Once you've created your matrices you can do useful stuff with them and as you'd expect, R has numerous built in functions to perform matrix operations. Some of the most common are given below. For example, to transpose a matrix we use the transposition function `t()`\index{t()}

```{r, echo=TRUE, eval=TRUE, collapse=TRUE}
my_mat_t <- t(my_mat)
my_mat_t
```

To extract the diagonal elements of a matrix and store them as a vector we can use the `diag()`\index{diag()} function

```{r, echo=TRUE, eval=TRUE, collapse=TRUE}
my_mat_diag <- diag(my_mat)
my_mat_diag
```

The usual matrix addition, multiplication etc can be performed. Note the use of the `%*%` operator to perform matrix multiplication.

```{r, echo=TRUE, eval=TRUE, collapse=TRUE}
mat.1 <- matrix(c(2, 0, 1, 1), nrow = 2)	# notice that the matrix has been filled 
mat.1                                     # column-wise by default

mat.2 <- matrix(c(1, 1, 0, 2), nrow = 2)
mat.2

mat.1 + mat.2			# matrix addition
mat.1 * mat.2			# element by element products
mat.1 %*% mat.2			# matrix multiplication
```

### Lists {#lists}

The next data structure we will quickly take a look at is a list. Whilst vectors and matrices are constrained to contain data of the same type, lists are able to store mixtures of data types. In fact we can even store other data structures such as vectors and arrays within a list or even have a list of a list. This makes for a very flexible data structure which is ideal for storing irregular or non-rectangular data (see [Chapter 7](#prog_r) for an example). 

To create a list we can use the `list()`\index{list()} function. Note how each of the three list elements are of different classes (character, logical, and numeric) and are of different lengths.

```{r, echo=TRUE, eval=TRUE, collapse=TRUE}
list_1 <- list(c("black", "yellow", "orange"),
               c(TRUE, TRUE, FALSE, TRUE, FALSE, FALSE),
               matrix(1:6, nrow = 3))
list_1
```

Elements of the list can be named during the construction of the list 

```{r, echo=TRUE, eval=TRUE, collapse=TRUE}
list_2 <- list(colours = c("black", "yellow", "orange"), 
               evaluation = c(TRUE, TRUE, FALSE, TRUE, FALSE, FALSE), 
               time = matrix(1:6, nrow = 3))
list_2
```

or after the list has been created using the `names()`\index{names()} function

```{r, echo=TRUE, eval=TRUE, collapse=TRUE}
names(list_1) <- c("colours", "evaluation", "time")
list_1
```

### Data frames {#df}

```{block2, vid-text8, type='rmdvideo'}
Take a look at this [video][dataf-vid] for a quick introduction to data frame objects in R

```

\  

By far the most commonly used data structure to store data in is the data frame. A data frame is a powerful two-dimensional object made up of rows and columns which looks superficially very similar to a matrix. However, whilst matrices are restricted to containing data all of the same type, data frames can contain a mixture of different types of data. Typically, in a data frame each row corresponds to an individual observation and each column corresponds to a different measured or recorded variable. This setup may be familiar to those of you who use LibreOffice Calc or Microsoft Excel to manage and store your data. Perhaps a useful way to think about data frames is that they are essentially made up of a bunch of vectors (columns) with each vector containing its own data type but the data type can be different between vectors. 


We can construct a data frame from existing data objects such as vectors using the `data.frame()`\index{data.frame()} function. As an example, let's create three vectors `p.height`, `p.weight` and `p.names` and include all of these vectors in a data frame object called `dataf`.

```{r dataf, echo=TRUE, collapse=TRUE}
p.height <- c(180, 155, 160, 167, 181)
p.weight <- c(65, 50, 52, 58, 70)
p.names <- c("Joanna", "Charlotte", "Helen", "Karen", "Amy")

dataf <- data.frame(height = p.height, weight = p.weight, names = p.names)
dataf
```

You'll notice that each of the columns are named with variable name we supplied when we used the `data.frame()` function. It also looks like the first column of the data frame is a series of numbers from one to five. Actually, this is not really a column but the name of each row. We can check this out by getting R to return the dimensions of the `dataf` object using the `dim()`\index{dim()} function. We see that there are 5 rows and 3 columns.

```{r dataf2, echo=TRUE, collapse=TRUE}
dim(dataf)   # 5 rows and 3 columns
```

Another really useful function which we use all the time is `str()`\index{str()} which will return a compact summary of the structure of the data frame object (or any object for that matter).

```{r dataf3, echo=TRUE, collapse=TRUE}
str(dataf)   
```

The `str()` function gives us the data frame dimensions and also reminds us that `dataf` is a `data.frame` type object. It also lists all of the variables (columns) contained in the data frame, tells us what type of data the variables contain and prints out the first five values. We often copy this summary and place it in our R scripts with comments at the beginning of each line so we can easily refer back to it whilst writing our code. We showed you how to comment blocks in RStudio [here](#proj_doc). 

Also notice that R has automatically decided that our `p.names` variable should be a character (`chr`) class variable when we first created the data frame. Whether this is a good idea or not will depend on how you want to use this variable in later analysis. If we decide that this wasn't such a good idea we can change the default behaviour of the `data.frame()` function by including the argument `stringsAsFactors = TRUE`. Now our strings are automatically converted to factors.

```{r dataf4, echo=TRUE, collapse=TRUE}
p.height <- c(180, 155, 160, 167, 181)
p.weight <- c(65, 50, 52, 58, 70)
p.names <- c("Joanna", "Charlotte", "Helen", "Karen", "Amy")

dataf <- data.frame(height = p.height, weight = p.weight, names = p.names, 
										stringsAsFactors = TRUE)
str(dataf)
```

\  

## Importing data

Although creating data frames from existing data structures is extremely useful, by far the most common approach is to create a data frame by importing data from an external file. To do this, you'll need to have your data correctly formatted and saved in a file format that R is able to recognise. Fortunately for us, R is able to recognise a wide variety of file formats, although in reality you'll probably end up only using two or three regularly. 

As an example, the data frame below is a subset of [Short Term Rental Applications](nola-str) and their status in Orleans Parish (City of New Orleans). It has Owner Name, Operator Name, Permit Type, Status, Expiration Date etc. In addition, it also has the number of bedrooms and occupancy limits.

In the base R, we typically use `read.csv` or `read.table` to read in an external file. Please pay attention to the file path and modify accordingly.

\  

```{r import-data-html, eval=knitr::is_html_output(), echo=FALSE, collapse=TRUE}
nola_str <- read.csv('data/NOLA_STR.csv', header = TRUE, stringsAsFactors = FALSE)
knitr::kable(rbind(head(nola_str), tail(nola_str)), row.names = FALSE)

str(nola_str)
```

```{r import-data-latex, eval=knitr::is_latex_output(), echo=F, collapse=T, warning=F, message=F}
library(kableExtra)
nola_str <- read.csv('data/NOLA_STR.csv', header = TRUE)
knitr::kable(rbind(head(nola_str), tail(nola_str)), row.names = FALSE, "latex", booktabs = T) %>% 
	kable_styling(latex_options = "striped")

str(nola_str)
```

\  

There are a couple of important things to bear in mind about data frames. 

* These types of objects are known as rectangular data (or tidy data) as each column must have the same number of observations. Also, any missing data should be recorded as an `NA` just as we did with our vectors. 
* R tries to guess the data type based on sampling a few rows. More often than not, it gets it wrong. This is why I explicitly specified stringsAsFactors = FALSE to prevent reading them as factors. Ideally you want to store variables such as Current.Status and Permit.Type as factors and Address and Operator.Name as character.
* Check to see how the date variables such as Issue_Date and Application.Date are read and stored. `str()` is often your friend.

\  

```{block2, vid-text9, type='rmdvideo'}
Take a look at this [video][import-vid] for a quick introduction to importing data in R

```

### Saving files to import

The easiest method of creating a data file to import into R is to enter your data into a spreadsheet using either Microsoft Excel or LibreOffice Calc and save the spreadsheet as a tab delimited file. We prefer LibreOffice Calc as it's open source, platform independent and free but MS Excel is OK too (but see [here][excel_gotcha] for some gotchas). I

There are a couple of things to bear in mind when saving files to import into R which will make your life easier in the long run. 

* Keep your column headings (if you have them) short and informative. Also avoid spaces in your column headings by replacing them with an underscore or a dot (i.e. replace `opertator name` with `operator_name` or `operator.name`) 
* Avoid using special characters (i.e. `floor area (ft^2)`).
* Remember, if you have missing data in your data frame (empty cells) you should use an `NA` to represent these missing values. This will keep the data frame tidy. 

### Import functions {#import_fnc}

Once you've saved your data file in a suitable format we can now read this file into R. The workhorse function for importing data into R is the `read.csv()`\index{read.csv()} function (we discuss some alternatives later in the chapter). The `read.csv()` function is a very flexible function with a shed load of arguments (see `?read.csv`) but it's quite simple to use. 

Let's import a tab delimited file called `NOLA_str.txt` which contains the data we saw previously in this [Chapter](#df) and assign it to an object called `str`. The file is located in a `data` directory which itself is located in our [root directory](#dir_struct). The first row of the data contains the variable (column) names. To use the `read.csv()` function to import this file

```{r df1, echo=TRUE, collapse=TRUE}
nola_str <- read.csv(file = 'data/nola_STR.csv', header = TRUE,
                        stringsAsFactors = FALSE)
```

There are a few things to note about the above command. First, the file path and the filename (including the file extension) needs to be enclosed in either single or double quotes (i.e. the `data/nola_STR.csv` bit) as the `read.csv()` function expects this to be a character string. If your working directory is already set to the directory which contains the file, you don’t need to include the entire file path just the filename. In the example above, the file path is separated with a single forward slash `/`. This will work regardless of the operating system you are using and we recommend you stick with this. However, Windows users may be more familiar with the single backslash notation and if you want to keep using this you will need to include them as double backslashes. Note though that the double backslash notation will **not** work on computers using Mac OSX or Linux operating systems. 

```{r df2, echo=TRUE, eval=FALSE}
nola_str <- read.csv(file = 'C:\\Documents\\Prog1\\data\\nola_STR.csv', 
                      header = TRUE, stringsAsFactors = FALSE)
```

The `header = TRUE` argument specifies that the first row of your data contains the variable names (i.e. `nitrogen`, `block` etc). If this is not the case you can specify `header = FALSE` (actually, this is the default value so you can omit this argument entirely). The `sep = "\t"` argument tells R that the file delimiter is a tab (`\t`).  

After importing our data into R it doesn't appear that R has done much, at least nothing appears in the R Console! To see the contents of the data frame we could just type the name of the object as we have done previously. **BUT** before you do that, think about why you're doing this. If your data frame is anything other than tiny, all you're going to do is fill up your Console with data. It's not like you can easily check whether there are any errors or that your data has been imported correctly. A much better solution is to use our old friend the `str()` function to return a compact and informative summary of your data frame.

```{r df3, echo=TRUE, collapse=TRUE}
str(nola_str) 
```

Here we see that `nola_str` is a 'data.frame' object which contains 89 rows and 13 variables (columns). Each of the variables are listed along with their data class and the first 10 values. As we mentioned previously in this Chapter, it can be quite convenient to copy and paste this into your R script as a comment block for later reference. 

From R version 4.0.0 you can just leave out this argument as `stringsAsFactors = FALSE` is the default. 


Other useful arguments include `dec =` and `na.strings =`. The `dec =` argument allows you to change the default character (`.`) used for a decimal point. This is useful if you're in a country where decimal places are usually represented by a comma (i.e. `dec = ","`). The `na.strings =` argument allows you to import data where missing values are represented with a symbol other than `NA`. This can be quite common if you are importing data from other statistical software such as Minitab which represents missing values as a `*` (`na.strings = "*"`). 

If we just wanted to see the names of our variables (columns) in the data frame we can use the `names()` function which will return a character vector of the variable names.

```{r df4.1, echo=TRUE, collapse=TRUE}
names(str)
```

`read.csv` is basically a thin wrapper around the workhorse function, `read.table`. R has a number of variants of the `read.table()` function that you can use to import a variety of file formats. Actually, these variants just use the `read.table()` function but include different combinations of arguments by default to help import different file types. Similar to `read.csv()`\index{read.csv()}, you can also use `read.csv2()`\index{read.csv2()} and `read.delim()`\index{read.delim()} functions. The `read.csv()` function is used to import comma separated value (.csv) files and assumes that the data in columns are separated by a comma (it sets `sep = ","` by default). It also assumes that the first row of the data contains the variable names by default (it sets `header = TRUE` by default). The `read.csv2()` function assumes data are separated by semicolons and that a comma is used instead of a decimal point (as in many European countries). The `read.delim()` function is used to import tab delimited data and also assumes that the first row of the data contains the variable names by default. 

```{r df5, echo=TRUE, eval=FALSE}
# import .csv file
nola_str <- read.csv(file = 'data/nola_STR.csv') 

# import .csv file with dec = "," and sep = ";"
nola_str <- read.csv2(file = 'data/nola_STR.csv') 

# import tab delim file with sep = "\t"
nola_str <- read.delim(file = 'data/nola_STR.txt') 
```

You can even import spreadsheet files from MS Excel or other statistics software, using packages,  directly into R but our advice is that this should generally be avoided if possible as it just adds a layer of uncertainty between you and your data. In our opinion it's almost always better to export your spreadsheets as tab or comma delimited files and then import them into R using the `read.table()` function. If you're hell bent on directly importing data from other software you will need to install the `foreign` package which has functions for importing Minitab, SPSS, Stata and SAS files or the `xlsx` package to import Excel spreadsheets. 

### Common import frustrations

It's quite common to get a bunch of really frustrating error messages when you first start importing data into R. Perhaps the most common is

```{r, eval=FALSE}
Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") :
  cannot open file 'nola_STR.csv': No such file or directory
```

This error message is telling you that R cannot find the file you are trying to import. It usually rears its head for one of a couple of reasons (or all of them!). The first is that you've made a mistake in the spelling of either the filename or file path. Another common mistake is that you have forgotten to include the file extension in the filename (i.e. `.txt`). Lastly, the file is not where you say it is or you've used an incorrect file path. Using RStudio [Projects](#rsprojs) and having a logical [directory structure](#dir_struct) goes along way to avoiding these types of errors.


### Other import options {#import_other}

There are numerous other functions to import data from a variety of sources and formats. Most of these functions are contained in packages that you will need to install before using them. We list a couple of the more useful packages and functions below. 

The `fread()`\index{fread} function from the `read.table` package \index{read.table package} is great for importing large data files quickly and efficiently (much faster than the `read.table()` function). One of the great things about the `fread()` function is that it will automatically detect many of the arguments you would normally need to specify (like `sep =` etc). One of the things you will need to consider though is that the `fread()` function will return a `data.table` object not a `data.frame` as would be the case with the `read.table()` function. This is usually not a problem as you can pass a `data.table` object to any function that only accepts `data.frame` objects. To learn more about the differences between `data.table` and `data.frame` objects see [here][data-table]. 

```{r df8, echo=TRUE, eval=FALSE}
library(read.table)
all_data <- fread(file = 'data/nola_str.txt')
```

Various functions from the `readr`\index{readr package} package are also very efficient at reading in large data files. The `readr` package is part of the '[tidyverse][tidyverse]' collection of packages and provides many equivalent functions to base R for importing data. The `readr` functions are used in a similar way to the `read.table()` or `read.csv()` functions and many of the arguments are the same (see `?readr::read_table` for more details). There are however some differences. For example, when using the `read_table()`\index{read\_table()} function the `header = TRUE` argument is replaced by `col_names = TRUE` and the function returns a `tibble` class object which is the tidyverse equivalent of a `data.frame` object (see [here][tibbles] for differences). \index{read\_csv()} \index{read\_delim()} \index{read\_tsv()}

In PLAN 672, we almost exclusively use functions from `readr` packages. I strongly recommend it. 

```{r df9, echo=TRUE, eval=FALSE}
library(readr)
# import white space delimited files
all_data <- read_table(file = 'data/nola_STR.txt', col_names = TRUE)

# import comma delimited files
all_data <- read_csv(file = 'data/nola_STR.txt')

# import tab delimited files
all_data <- read_delim(file = 'data/nola_STR.txt', delim = "\t")

# or use
all_data <- read_tsv(file = 'data/nola_STR.txt')
```

If your data file is ginormous, then the `ff`\index{ff package} and `bigmemory`\index{bigmemory package} packages may be useful as they both contain import functions that are able to store large data in a memory efficient manner. You can find out more about these functions [here][ff] and [here][bigmem].


## Wrangling data frames

Now that you're able to successfully import your data from an external file into R our next task is to do something useful with our data. Working with data is a fundamental skill which you'll need to develop and get comfortable with as you'll likely do a lot of it during any project. The good news is that R is especially good at manipulating, summarising and visualising data. Manipulating data (often known as data wrangling or munging) in R can at first seem a little daunting for the new user but if you follow a few simple logical rules then you'll quickly get the hang of it, especially with some practice.  

\  

```{block2, vid-text10, type='rmdvideo'}
See this [video][dataw-vid] for a general overview on how to use positional and logical indexes to extract data from a data frame object in R

```

\  

Let's remind ourselves of the structure of the `str` data frame we imported in the previous section. 

```{r dw1, echo=TRUE, collapse=TRUE}
nola_str <- read.table(file = 'data/nola_STR.txt', header = TRUE, sep = "\t")
str(nola_str)
```

To access the data in any of the variables (columns) in our data frame we can use the `$` notation. For example, to access the `Bedroom.Limit` variable in our `nola_str` data frame we can use `nola_str$Bedroom.Limit `. This tells R that the `Bedroom.Limit` variable is contained within the data frame `nola_str`.

```{r dw2, echo=TRUE, collapse=TRUE}
nola_str$Bedroom.Limit 
```

This will return a vector of the `Bedroom.Limit ` data. If we want we can assign this vector to another object and do stuff with it, like calculate a mean or get a summary of the variable using the `summary()`\index{summary()} function.

```{r dw3, echo=TRUE, collapse=TRUE}
f_bedroom_limit <- nola_str$Bedroom.Limit 
mean(f_bedroom_limit)
summary(f_bedroom_limit)
```

Or if we don't want to create an additional object we can use functions 'on-the-fly' to only display the value in the console.

```{r dw3.1, echo=TRUE, collapse=TRUE}
mean(nola_str$Bedroom.Limit)
summary(nola_str$Bedroom.Limit)
```

Alternately, you can also use pipes.

```{r dw3.2, echo=TRUE, collapse=TRUE}
nola_str$Bedroom.Limit |> mean()
nola_str$Bedroom.Limit |> summary()
```


Just as we did with [vectors](#vectors), we also can access data in data frames using the square bracket `[ ]` notation. However, instead of just using a single index, we now need to use two indexes, one to specify the rows and one for the columns. To do this, we can use the notation `my_data[rows, columns]` where `rows` and `columns` are indexes and `my_data` is the name of the data frame. Again, just like with our vectors our indexes can be positional or the result of a logical test. 

### Positional indexes

To use positional indexes we simple have to write the position of the rows and columns we want to extract inside the `[ ]`. For example, if for some reason we wanted to extract the first value (1^st^ row ) of the `height` variable (4^th^ column)

```{r dw4, echo=TRUE, collapse=TRUE}
nola_str[1, 4]

# this would give you the same
nola_str$Bedroom.Limit[1]
```

We can also extract values from multiple rows or columns by specifying these indexes as vectors inside the `[ ]`. To extract the first 10 rows and the first 4 columns we simple supply a vector containing a sequence from 1 to 10 for the rows index (`1:10`) and a vector from 1 to 4 for the column index (`1:4`).

```{r dw5, echo=TRUE, collapse=TRUE}
nola_str[1:10, 1:4]
```

Or for non sequential rows and columns then we can supply vectors of positions using the `c()` function. To extract the 1^st^, 5^th^, 12^th^, 30^th^ rows from the 1^st^, 3^rd^, 6^th^ and 8^th^ columns

```{r dw6, echo=TRUE, collapse=TRUE}
nola_str[c(1, 5, 12, 30), c(1, 3, 6, 8)]
```

All we are doing in the two examples above is creating vectors of positions for the rows and columns that we want to extract. We have done this by using the skills we developed in [Chapter 2](#funcs) when we generated vectors using the `c()` function or using the `:` notation.

But what if we want to extract either all of the rows or all of the columns? It would be extremely tedious to have to generate vectors for all rows or for all columns. Thankfully R has a shortcut. If you don't specify either a row or column index in the `[ ]` then R interprets it to mean you want all rows or all columns. For example, to extract the first 8 rows and all of the columns in the `flower` data frame

```{r dw7, echo=TRUE, collapse=TRUE}
nola_str[1:8, ]
```

or all of the rows and the first 3 columns. If you're reading the web version of this book scroll down in output panel to see all of the data. Note, if you're reading the pdf version of the book some of the output has been truncated to save some space.

```{r dw8, echo=TRUE, eval=FALSE}
nola_str[, 1:3]
```

```{r dw8-html, echo=FALSE, collapse=TRUE, eval=knitr::is_html_output(), warning=FALSE, attr.output='style="max-height: 500px;"'}
nola_str[, 1:3]
```

```{r dw8-latex, echo=FALSE, collapse=TRUE, eval=knitr::is_latex_output(), warning=FALSE}
rbind(head(nola_str[, 1:3], n= 10), tail(nola_str[, 1:3], n= 10))
```

We can even use negative positional indexes to exclude certain rows and columns. As an example, lets extract all of the rows except the first 85 rows and all columns except the 4^th^, 7^th^ and 8^th^ columns. Notice we need to use `-()` when we generate our row positional vectors. If we had just used `-1:85` this would actually generate a regular sequence from -1 to 85 which is not what we want (we can of course use `-1:-85`).

```{r dw9, echo=TRUE, collapse=TRUE}
nola_str[-(1:85), -c(4, 7, 8)]
```

In addition to using a positional index for extracting particular columns (variables) we can also name the variables directly when using the square bracket `[ ]` notation. For example, let's extract the first 5 rows and the variables `treat`, `nitrogen` and `leafarea`. Instead of using `str[1:5, c(1, 2, 6)]` we can instead use

```{r dw10, echo=TRUE, collapse=TRUE}
nola_str[1:5, c("Operator.Name", "License.Holder.Name", "Application.Date")]
```

We often use this method in preference to the positional index for selecting columns as it will still give us what we want even if we've changed the order of the columns in our data frame for some reason. 

### Logical indexes

Just as we did with vectors, we can also extract data from our data frame based on a logical test. We can use all of the logical operators that we used for our vector examples so if these have slipped your mind maybe [pop back](#Logical-index) and refresh your memory.  Let's extract all rows where `Bedroom.Limit` is greater than 3 and extract all columns by default (remember, if you don't include a column index after the comma it means all columns).

```{r dw11, echo=TRUE, collapse=TRUE}
big_str <- nola_str[nola_str$Bedroom.Limit > 3, ]
big_str
```

Notice in the code above that we need to use the `nola_str$Bedroom.Limit` notation for the logical test. If we just named the `Bedroom.Limit` variable without the name of the data frame we would receive an error telling us R couldn't find the variable `nola_str$Bedroom.Limit`. The reason for this is that the `nola_str$Bedroom.Limit` variable only exists inside the `nola_str` data frame so you need to tell R exactly where it is.

```{r dw12, echo=TRUE, eval=FALSE}
big_str <- nola_str[Bedroom.Limit > 3, ]
Error in `[.data.frame`(nola_str, Bedroom.Limit > 3, ) : 
  object 'Bedroom.Limit' not found
```

So how does this work? The logical test is `nola_str$Bedroom.Limit > 3` and R will only extract those rows that satisfy this logical condition. If we look at the output of just the logical condition you can see this returns a vector containing `TRUE` if `Bedroom.Limit` is greater than 3 and `FALSE` if `Bedroom.Limit` is not greater than 3.

```{r dw13, echo=TRUE, collapse=TRUE}
nola_str$Bedroom.Limit > 3
```

So our row index is a vector containing either `TRUE` or `FALSE` values and only those rows that are `TRUE` are selected.

Other commonly used operators are shown below

```{r dw14, echo=TRUE, eval=FALSE}
nola_str[nola_str$Bedroom.Limit >= 3, ]       # values greater or equal to 3

nola_str[nola_str$Bedroom.Limit <= 3, ]        # values less than or equal to 3

nola_str[nola_str$Bedroom.Limit <= 4, ]       # values  equal to 4

nola_str[nola_str$Bedroom.Limit != 4, ]        # values  not equal to 4
```

We can also extract rows based on the value of a character string or factor level. Let's extract all rows where the `Operator.Name`  is equal to `Michael Heyne` (again we will output all columns). Notice that the double equals `==` sign must be used for a logical test and that the character string must be enclosed in either single or double quotes (i.e. `"Michael Heyne"`). 

```{r dw15, echo=TRUE,eval=FALSE}
k <- nola_str[nola_str$Operator.Name  == "Michael Heyne", ]        
k
```

```{r dw15-html, echo=FALSE, collapse=TRUE, eval=knitr::is_html_output(), warning=FALSE, attr.output='style="max-height: 500px;"'}
k <- nola_str[nola_str$Operator.Name  == "Michael Heyne", ]        
k
```



Or we can extract all rows where `Current.Status`  is not equal to `Pending` (using `!=`) and only return columns 1 to 4. 

```{r dw16, echo=TRUE, eval=FALSE}
nola_str_notPending <- nola_str[nola_str$Current.Status  != "Pending", 1:4]        
nola_str_notPending 
```

```{r dw16-html, echo=FALSE, collapse=TRUE, eval=knitr::is_html_output(), warning=FALSE, attr.output='style="max-height: 500px;"'}
nola_str_notPending <- nola_str[nola_str$Current.Status  != "Pending", 1:4]        
nola_str_notPending 
```

```{r dw16-latex, echo=FALSE, collapse=TRUE, eval=knitr::is_latex_output(), warning=FALSE}
nola_str_notPending <- nola_str[nola_str$Current.Status  != "Pending", 1:4]       
rbind(head(nola_str_notPending, n = 10), tail(nola_str_notPending, n = 10))
```

We can increase the complexity of our logical tests by combining them with [Boolean expressions][boolean] just as we did for vector objects. For example, to extract all rows where `Bedroom.Limit` is greater or equal to `3` AND `Current.Status` is equal to `Pending` AND `Permit.Type` is equal to `Short Term Rental Residential Owner"` we combine a series of logical expressions with the `&` symbol. 

```{r dw17, echo=TRUE, collapse=TRUE}
k2 <- nola_str[nola_str$Bedroom.Limit >= 3 & 
							 	nola_str$Current.Status == "Pending" &
							 nola_str$Permit.Type == "Short Term Rental Residential Owner", 
							 ]        
k2[,1:5]
```

To extract rows based on an 'OR' Boolean expression we can use the `|` symbol. Don't forget the `,` to specify and extract the column indices.

```{r dw17.1, echo=TRUE, collapse=TRUE}
k3 <- nola_str[nola_str$Bedroom.Limit >= 3 | 
							 	nola_str$Current.Status != "Pending", 
							 1:3]  

k3
```




### Adding columns and rows

Sometimes it's useful to be able to add extra rows and columns of data to our data frames. There are multiple ways to achieve this (as there always is in R!) depending on your circumstances. To simply append additional rows to an existing data frame we can use the `rbind()`\index{rbind()} function and to append columns the `cbind()`\index{cbind()} function. Let's create a couple of test data frames to see this in action using our old friend the `data.frame()` function.

```{r dw25, echo=TRUE, collapse=TRUE}
# rbind for rows
df1 <- data.frame(id = 1:4, height = c(120, 150, 132, 122),
						weight = c(44, 56, 49, 45))
df1

df2 <- data.frame(id = 5:6, height = c(119, 110),
						weight = c(39, 35))
df2

df3 <- data.frame(id = 1:4, height = c(120, 150, 132, 122),
						weight = c(44, 56, 49, 45))
df3

df4 <- data.frame(location = c("UK", "CZ", "CZ", "UK"))
df4
```

We can use the `rbind()` function to append the rows of data in `df2` to the rows in `df1` and assign the new data frame to `df_rcomb`.

```{r dw25.1, echo=TRUE, collapse=TRUE}
df_rcomb <- rbind(df1, df2)
df_rcomb
```

And `cbind` to append the column in `df4` to the `df3` data frame and assign to df_ccomb`.

```{r dw25.2, echo=TRUE, collapse=TRUE}
df_ccomb <- cbind(df3, df4)
df_ccomb
```

Another situation when adding a new column to a data frame is useful is when you want to perform some kind of transformation on an existing variable. For example, say we wanted to apply a log~10~ transformation on the height variable in the `df_rcomb` data frame we created above. We could just create a separate variable to contains these values but it's good practice to create this variable as a new column inside our existing data frame so we keep all of our data together. Let's call this new variable `height_log10`.  

```{r dw26, echo=TRUE, collapse=TRUE}
# log10 transformation
df_rcomb$height_log10 <- log10(df_rcomb$height)
df_rcomb
```

This situation also crops up when we want to convert an existing variable in a data frame from one data class to another data class. For example, the `id` variable in the `df_rcomb` data frame is numeric type data (use the `str()` or `class()` functions to check for yourself). If we wanted to convert the `id` variable to a factor to use later in our analysis we can create a new variable called `Fid` in our data frame and use the `factor()`\index{factor()} function to convert the `id` variable. 

```{r dw27, echo=TRUE, collapse=TRUE}
# convert to a factor 
df_rcomb$Fid <- factor(df_rcomb$id)
df_rcomb
str(df_rcomb)
```


## Summarising data frames

Now that we're able to manipulate and extract data from our data frames our next task is to start exploring and getting to know our data. In this section we'll start producing tables of useful summary statistics of the variables in our data frame and in the next two Chapters we'll cover visualising our data with base R graphics and using the `ggplot2` package. 

A really useful starting point is to produce some simple summary statistics of all of the variables in our `str` data frame using the `summary()`\index{summary()} function.

```{r sum1, echo=TRUE, collapse=TRUE}
nola_str$Permit.Type <- factor(nola_str$Permit.Type)
nola_str$Current.Status <- factor(nola_str$Current.Status)
summary(nola_str)
```

For numeric variables  the mean, minimum, maximum, median, first (lower) quartile and third (upper) quartile are presented. For factor variables (i.e. `Permit.Type` and `current.status`) the number of observations in each of the factor levels is given. If a variable contains missing data then the number of `NA` values is also reported. For character variables, only length of the vector is reported.

If we wanted to summarise a smaller subset of variables in our data frame we can use our indexing skills in combination with the `summary()` function. Notice we include all rows by not specifying a row index.  

```{r sum2, echo=TRUE, collapse=TRUE}
summary(nola_str[, 4:7])

```

And to summarise a single variable.

```{r sum3, echo=TRUE, collapse=TRUE}
summary(nola_str$Permit.Type)

```

As you've seen above, the `summary()` function reports the number of observations in each level of our factor variables. Another useful function for generating tables of counts is the `table()`\index{table()} function. The `table()` function can be used to build contingency tables of different combinations of factor levels. For example, to count the number of observations for each level of `Permit.Type`

```{r sum4, echo=TRUE, collapse=TRUE}
table(nola_str$Permit.Type)
```

We can extend this further by producing a table of counts for each combination of `Permit.Type` and `Current.Status` factor levels.

```{r sum5, echo=TRUE, collapse=TRUE}
table(nola_str$Permit.Type, nola_str$Current.Status)
```

A more flexible version of the `table()` function is the `xtabs()`\index{xtabs()} function. The `xtabs()` function uses a formula notation (`~`) to build contingency tables with the cross-classifying variables separated by a `+` symbol on the right hand side of the formula. `xtabs()` also has a useful `data =` argument so you don't have to include the data frame name when specifying each variable. 

```{r sum6, echo=TRUE, collapse=TRUE}
xtabs(~ Permit.Type + Current.Status, data = nola_str)
```



## Exporting data

By now we hope you're getting a feel for how powerful and useful R is for manipulating and summarising data (and we've only really scratched the surface). One of the great benefits of doing all your data wrangling in R is that you have a permanent record of all the things you've done to your data. Gone are the days of making undocumented changes in Excel or Calc! By treating your data as 'read only' and documenting all of your decisions in R you will have made great strides towards making your analysis more reproducible and transparent to others. It's important to realise, however, that any changes you've made to your data frame in R will not change the original data file you imported into R (and that's a good thing). Happily it's straightforward to export data frames to external files in a wide variety of formats.



## Exercise 3

```{block2, note-text3, type='rmdtip'}
Congratulations, you've reached the end of Chapter 3! Perhaps now's a good time to practice some of what you've learned. You can find an exercise we've prepared for you [here][exercise3]. If you want to see our solutions for this exercise you can find them [here][exercise3-sol] (don't peek at them too soon though!).   
```

```{r, child="links.md"}
```

